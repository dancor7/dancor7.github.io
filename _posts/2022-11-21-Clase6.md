---
layout: post
title: Clase 6 - FAccT en IA
---

## Introduccion

Estamos en una epoca de tremenda innovacion y crecimiento en tecnologia, tenemos una inmensa cantidad de emprendimientos basados en AI, construyendo modelos para diferentes problemas. Esto lo podemos comparar a cuando la raza humana empezo a crear construcciones más complejas, empezaron a construir puentes y edificios más grandes. Pero no podemos olvidar que cuando la raza humana empezo a construir esto, hubieron problemas, puentes se cayeron, edificios colapsaron y personas fueron heridas. De esta misma manera, existe un peligro al comercializar IA, es que aun estamos en los primeros pasos deesta, e igual como nuestros antepasados hirieron a personas cuando estaban construyendo puentes por primera vez, puede ocurrir lo mismo con IA en esta etapa.

Dado esto, se ha trabajado para ayudar a introducir IA al publico de manera comercial, y se ha establecido una base llamada FAccT por sus siglas en ingles, traducidas al español se enfocan en justicia, rendimiento de cuentas y transparencia. Esto es aplicable para toda herramienta que tenga a IA como parte importante de si, incluyendo a sistemas recomendadores. Esto es porque los SysRec se enfocan en ayudar a personas a filtrar sonidos, identificando items de importancia ante un gran espacio de informacion. Estan usualmente optimizados en precision y metricas academicas, no en justicia.

## Caso de Youtube

Si miramos el algoritmo de Youtube usado entre 2016 y 2019 para recomendar videos a usuarios, vemos un comportamiento interesante. Existian 2 algoritmos que trabajan como un ecosistema, uno clasifica los videos y un segundo algoritmo usa estas clasificaciones para recomendar estos videos a distintos usuarios. Los algoritmos usan informacion del video, informacion de los usuarios que miran el video, metadata del video y geolocalizacion. De esta manera, Youtube buscaba mantener a usuarios saltando de un video a otro, idealmente llevandolos a videos más largos y más populares, logranto retencion y de esta manera, aumentando el valor de sus ads. 

El problema que este caso presenta, es que el unico interes del modelo es que un usuario vea más y más videos, sin importar el contenido de estos. No importa si son videos borderline, con desnudos, violencia y visiones extremistas, solo importa la cantidad de tiempo en que el video fue mirado. Claramente existe lo que podriamos llamar una falta de etica por parte de la recomendación.

## FAccT

Dada la importancia que la IA va tomando con las grandes empresas y como estas van exponiendo al publico a estas, como en el caso de Youtube, esta tremenda empresa que existe en la casa de toda persona con acceso a internet y que ya les aplica IA. Dado esto se invoco a una conferencia determinada como FAccT (fairness, accountability and transparency) y en esta se levanto los siguientes puntos:

- Necesitamos que una IA sea justa, independiente del sesgo que pueda existir en la data, debe ser capaz de detectarla y modificarla para evitar que se genere discriminacion u odio a grupos
- Necesitamos que una IA tenga una persona o un grupo responsable por errores o injusticias que cometa, por ejemplo si Youtube recomienda videos borderline, cualquier accion en contra de eso debe ser dada a Youtube
-  Necesitamos entender porque una IA da los resultados que entrega, ya que de esta manera podemos entender y regular los modelos. Esto ayuda interpretar los resultados, entender que variables o modificaciones en la data crean los sesgos causados, lo cual es util tanto para la empresa que la usa para mejores insights y tambien para los entes reguladores que necesitan asignar la responsabilidad y seguir pasos legales al respecto

## Conclusion

Estamos caminando como sociedad para poder tener IA de calidad que nos ayude a ser mejores humanos, aun quedan muchos pasos todavia y tal vez no ocurra en el futuro cercano, pero mientras siempre estemos caminando hacia delante, estaremos bien.






